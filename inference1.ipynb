{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "import os\n",
    "from PIL import Image\n",
    "import json,requests\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "use_cuda= torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64,re\n",
    "def img_to_base64(img_path):\n",
    "    with open(img_path, 'rb')as read:\n",
    "        b64 = base64.b64encode(read.read())\n",
    "    return b64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from socr import ocr\n",
    "images=[]\n",
    "paths=[('xx','data')]\n",
    "img_txt=dict()\n",
    "if os.path.exists('ocr.txt'):\n",
    "    for line in open('ocr.txt','r').readlines():\n",
    "        # print(line)\n",
    "        if line :\n",
    "            line=line.strip()\n",
    "            # print(line)\n",
    "            [img_path,txt,origin]=line.split('####')\n",
    "            # img_txt[img_path]=txt\n",
    "            images.append((img_path,txt,origin))\n",
    "else:\n",
    "    writer=open('ocr.txt','w')\n",
    "    for _path in paths:\n",
    "        files=os.walk(_path[1])\n",
    "        print(files)\n",
    "        for x in files:\n",
    "            print(x)\n",
    "            sub_dir=x[0]\n",
    "            sub_files=x[2]\n",
    "            for im in sub_files:\n",
    "                if im.endswith('.DS_Store'):\n",
    "                    continue\n",
    "                real_path=os.path.join(sub_dir,fr'{im}')\n",
    "                \n",
    "                real_words,origin=ocr(img_to_base64(real_path))\n",
    "                print(real_path,real_words,origin)\n",
    "                images.append((real_path,real_words))\n",
    "                writer.write(f'{real_path}####{real_words}####{origin}\\n')\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = torch.nn.Sequential(*list(models.resnext101_32x8d(pretrained=True).children())[:-1])\n",
    "if use_cuda:\n",
    "    feature_extractor=feature_extractor.cuda()\n",
    "op_resize=T.Resize(size=(256,256))\n",
    "op_norm=T.Normalize(\n",
    "       mean=[0.485, 0.456, 0.406],\n",
    "       std=[0.229, 0.224, 0.225]\n",
    "   )\n",
    "convert_tensor = T.ToTensor()\n",
    "image_index=dict()\n",
    "import faiss                   # make faiss available\n",
    "faiss_index=dict()\n",
    "for image_path in images:\n",
    "    img = Image.open(fr'{image_path[0]}').convert('RGB')\n",
    "    img=op_resize(img)\n",
    "    img=convert_tensor(img).view(1,3,256,256)\n",
    "    if use_cuda:\n",
    "        img=img.cuda()\n",
    "    img=op_norm(img)\n",
    "    img_feature=feature_extractor(img)\n",
    "    if image_path[1] not in faiss_index.keys():\n",
    "        faiss_index[image_path[1]]=faiss.IndexFlatL2(2048)   # build the index\n",
    "    if image_path[1] not in image_index.keys():\n",
    "        image_index[image_path[1]]=[]\n",
    "    faiss_index[image_path[1]].add(img_feature.detach().cpu().view(1,-1).numpy())\n",
    "    image_index[image_path[1]].append(image_path[0])\n",
    "print(faiss_index['一年级下册'].ntotal)\n",
    "print(image_index['一年级下册'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import torchvision.transforms as T\n",
    "perspective_transformer = T.RandomPerspective(distortion_scale=0.2, p=1.0)\n",
    "id=random.randint(0,len(images)-1)\n",
    "# img1 = Image.open(images[id][0]).convert('RGB')\n",
    "# real_words=ocr(img_to_base64(images[id][0]))\n",
    "img_path='1.jpg'\n",
    "img1 = Image.open(img_path).convert(\"RGB\")\n",
    "real_words=ocr(img_to_base64(img_path))\n",
    "real_words=(real_words[0].replace('乐','六').replace('小','八').replace('书册','上册'),real_words[1])\n",
    "print('输入---',real_words[0],real_words[1])\n",
    "img1=op_resize(img1)\n",
    "# img1=perspective_transformer(img1)\n",
    "img=convert_tensor(img1).view(1,3,256,256)\n",
    "if use_cuda:\n",
    "    img=img.cuda()\n",
    "img=op_norm(img)\n",
    "img_feature=feature_extractor(img).detach().cpu().view(1,-1).numpy()\n",
    "print(f'img_feature={img_feature.shape}')\n",
    "NN=10\n",
    "D, I = faiss_index[real_words[0]].search(img_feature, NN)\n",
    "pred_ids=[I[0][i] for i in range(NN)]\n",
    "print(pred_ids,D,I)\n",
    "plt.imshow(img1)\n",
    "def get_concat_h(im1,img):\n",
    "    height= im1.height if im1.height > img.height else img.height\n",
    "    dst = Image.new('RGB', (im1.width + img.width, height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(img, (im1.width, 0))\n",
    "    return dst\n",
    "dst=Image.open(image_index[real_words[0]][pred_ids[0]]).convert(\"RGB\")\n",
    "\n",
    "for i in range(1,NN):\n",
    "    img = Image.open(image_index[real_words[0]][pred_ids[i]]).convert(\"RGB\")\n",
    "    dst=get_concat_h(dst,img)\n",
    "plt.imshow(dst)\n",
    "plt.show()\n",
    "plt.imshow(img1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "perspective_transformer = T.RandomPerspective(distortion_scale=0.2, p=1.)\n",
    "correct1=0\n",
    "correct2=0\n",
    "count=0\n",
    "image_paths=[_[0] for _ in images]\n",
    "for i in range(100):\n",
    "    id=random.randint(0,len(images)-1)\n",
    "    img1 = Image.open(fr'{images[id][0]}').convert('RGB')\n",
    "    real_words=ocr(img_to_base64(images[id][0]))[0]\n",
    "    img1=op_resize(img1)\n",
    "    img1=perspective_transformer(img1)\n",
    "    img=convert_tensor(img1).view(1,3,256,256)\n",
    "    if use_cuda:\n",
    "        img=img.cuda()\n",
    "    img=op_norm(img)\n",
    "    img_feature=feature_extractor(img).detach().cpu().view(1,-1).numpy()\n",
    "    D, I = faiss_index[real_words].search(img_feature, 5)\n",
    "    pred_ids=[I[0][i] for i in range(5)]\n",
    "    distances=[D[0][i] for i in range(5)]\n",
    "    # print('输入---',real_words,pred_ids[0])\n",
    "    if fr'{images[id][0]}' in image_index[real_words]:\n",
    "        if image_index[real_words].index(fr'{images[id][0]}')  in pred_ids:\n",
    "            correct1+=1        \n",
    "        if image_index[real_words].index(fr'{images[id][0]}')  == pred_ids[0]:\n",
    "            correct2+=1\n",
    "    else:\n",
    "        continue\n",
    "    count+=1\n",
    "print('top4准确率：',correct1/count)\n",
    "print('top1准确率：',correct2/count)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8df3d1517783d6501a5bbc15eb3f9a815bbe92334e0cfef809ecc9c571e9cac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
